# fine_tune_llama3_with_ORPO  
通过ORPO的方法微调llama3  

创新点：结合SFT和对齐学习的新尝试  

环境：最好使用colab L4（需要开PRO）

参考论文《ORPO: Monolithic Preference Optimization without Reference Model》 

reference to blog:https://mlabonne.github.io/blog/posts/2024-04-19_Fine_tune_Llama_3_with_ORPO.html 

